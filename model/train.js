const tf = require('@tensorflow/tfjs');
const FormData = require('form-data');
const fetch = require('node-fetch'); // c·∫ßn c√†i: npm install node-fetch@2
const readline = require('readline');

function askYesNo(question) {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout
  });

  return new Promise((resolve) => {
    rl.question(question + ' (y/n): ', (answer) => {
      rl.close();
      resolve(answer.trim().toLowerCase() === 'y');
    });
  });
}

async function getDataFromThuhuyen() {
    try {
        const response = await fetch("https://thuhuyen.fun/xg79/get_data.php");

        if (!response.ok) {
            throw new Error(`L·ªói HTTP: ${response.status}`);
        }

        const data = await response.json();
        return data.data;
    } catch (error) {
        console.error("L·ªói k·∫øt n·ªëi:", error);
        return null;
    }
}
function handleProgress(progress_i) {
    const prg = progress_i.slice(30, 40);
    let row = [];

    prg.forEach((e) => {
        row.push(parseFloat((e[1].bc / e[0].bc).toFixed(2)));
        row.push(parseFloat((e[1].v / e[0].v).toFixed(2)));
    });
    return row;
}
function hasNaN1D(array) {
    return array.some(value => isNaN(value));
}

// B∆∞·ªõc 2: X·ª≠ l√Ω d·ªØ li·ªáu
function preprocessData(data) {
    const data_parser = data.map((e) => JSON.parse(e.progress));
    let example = handleProgress(data_parser[0])
    // const ys = data.map((e) => (+e.d1 + +e.d2 + +e.d3 > 10 ? [1] : [0]));
    // const xs = data_parser.map((e) => handleProgress(e));
    let xs = []
    let ys = []
    for(let i=0; i< data.length; i++){
        let x = handleProgress(data_parser[i]);
        let y = (+data[i].d1 + +data[i].d2 + +data[i].d3 > 10 ? [1] : [0])
        if(x.length === example.length && !hasNaN1D(x) && !isNaN(y[0])){
            xs.push(x);
            ys.push(y)
        }
    }

    return { xs, ys };
}

// // B∆∞·ªõc 3: ƒê√†o t·∫°o v√† l∆∞u m√¥ h√¨nh l√™n server
// async function trainModel(xs, ys) {a
//     const model = tf.sequential();
//     model.add(tf.layers.dense({
//         units: 10,
//         inputShape: [xs[0].length],
//         activation: "relu"
//     }));
//     model.add(tf.layers.dense({ units: 1, activation: "sigmoid" }));

//     model.compile({
//         optimizer: tf.train.adam(),
//         loss: tf.losses.meanSquaredError,
//     });

//     const xs = tf.tensor2d(xs);
//     const ys = tf.tensor2d(ys);

//     await model.fit(xs, ys, {
//         epochs: 500,
//         callbacks: {
//             onEpochEnd: (epoch, logs) => {
//                 if (epoch % 100 === 0) {
//                     console.log(`Epoch ${epoch}: loss = ${logs.loss}`);
//                 }
//             },
//         },
//     });

//     // G·ª≠i model l√™n server
//     await uploadModel(model);

//     return model;
// }

// // B∆∞·ªõc 4: G·ª≠i m√¥ h√¨nh l√™n server th√¥ng qua API
async function uploadModel(model) {
    await model.save(tf.io.withSaveHandler(async (modelArtifacts) => {
        const form = new FormData();

        // JSON metadata
        const modelJson = JSON.stringify({
            modelTopology: modelArtifacts.modelTopology,
            format: 'layers-model',
            generatedBy: 'TensorFlow.js',
            convertedBy: null,
            weightsManifest: [{
                paths: ['weights.bin'],
                weights: modelArtifacts.weightSpecs,
            }]
        });

        form.append('model.json', Buffer.from(modelJson), {
            contentType: 'application/json',
            filename: 'model.json'
        });

        // Weights data
        form.append('weights.bin', Buffer.from(modelArtifacts.weightData), {
            contentType: 'application/octet-stream',
            filename: 'weights.bin'
        });
        const response = await fetch('https://thuhuyen.fun/xg79/upload_model.php', {
            method: 'POST',
            headers: form.getHeaders(),
            body: form
        });

        const text = await response.text(); // ho·∫∑c response.json() n·∫øu PHP tr·∫£ v·ªÅ JSON
        console.log("üì¶ Server response:", response.status, text);

        if (!response.ok) {
            throw new Error("‚ùå Upload model failed");
        }

        console.log("‚úÖ Model uploaded successfully!");
    }));
}
// // B∆∞·ªõc 5: D·ª± ƒëo√°n b·∫±ng m√¥ h√¨nh t·∫£i t·ª´ server


// async function loadModelFromServer() {
//     model = await tf.loadLayersModel('/models/model.json');
//     console.log("Model loaded from server.");
// }

// async function predict(progress) {
//     if (!model) {
//         await loadModelFromServer();
//     }

//     const inputData = handleProgress(progress);
//     const inputTensor = tf.tensor2d([inputData]);
//     const output = model.predict(inputTensor);
//     const value = (await output.data())[0];
//     return value >= 0.5 ? 1 : 2;
// }

// // B∆∞·ªõc 6: H√†m t·ªïng
async function build() {
    const rawData = await getDataFromThuhuyen();
    if (!rawData) return;

    const { xs, ys } = preprocessData(rawData);


    const inputTensor = tf.tensor2d(xs);
    const labelTensor = tf.tensor2d(ys);

    const model = tf.sequential();
    model.add(tf.layers.dense({ units: 100, activation: 'relu', inputShape: [xs[0].length] }));
    model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));

    model.compile({
        optimizer: 'sgd',
        loss: 'binaryCrossentropy',
        metrics: ['accuracy']
    });

    await model.fit(inputTensor, labelTensor, {
        epochs: 500,
        batchSize: 32,
        callbacks: {
            onEpochEnd: (epoch, logs) => {
                console.log(`Epoch ${epoch}: loss = ${logs.loss}, acc = ${logs.acc || logs.accuracy}`);
            }
        }
    });
    
    const confirm = await askYesNo("B·∫°n c√≥ mu·ªën l∆∞u m√¥ h√¨nh l√™n server kh√¥ng?");
    if (confirm) {
      await uploadModel(model);
      console.log("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u.");
    } else {
      console.log("‚ùå Kh√¥ng l∆∞u m√¥ h√¨nh.");
    }
}




build()
